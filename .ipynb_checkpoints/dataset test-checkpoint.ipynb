{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# encoding: utf-8\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = \"/home/dua/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+\"TRAIN.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trainlist, 'r') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle=True\n",
    "\n",
    "if shuffle:\n",
    "    random.shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "nSamples  = len(lines[:60]) if debug  else len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "length = 2000\n",
    "# length = None\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class listDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, root, length = None, shuffle=True,  train=False, dataset = None ,debug = False):\n",
    "#         with open(root, 'r') as file:\n",
    "#             self.lines = file.readlines()\n",
    "\n",
    "#         if shuffle:\n",
    "#             random.shuffle(self.lines)\n",
    "\n",
    "#         self.nSamples  = len(self.lines[:60]) if debug  else len(self.lines)\n",
    "\n",
    "#         self.train = train\n",
    "#         self.length = length\n",
    "#         self.dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __len__(self):\n",
    "#         return self.nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "assert index <= nSamples, 'index range error'\n",
    "imgpath = lines[index].rstrip()\n",
    "\n",
    "\n",
    "#         if self.train == True:\n",
    "#             img, label_index = self.load_data_label(imgpath)\n",
    "#             img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "#         else:\n",
    "#             img, label_index = self.load_test_data_label(imgpath)\n",
    "#             # img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "\n",
    "#         return (img ,label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __getitem__(self, index):\n",
    "\n",
    "#         assert index <= len(self), 'index range error'\n",
    "#         imgpath = self.lines[index].rstrip()\n",
    "\n",
    "\n",
    "#         if self.train == True:\n",
    "#             img, label_index = self.load_data_label(imgpath)\n",
    "#             img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "#         else:\n",
    "#             img, label_index = self.load_test_data_label(imgpath)\n",
    "#             # img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "\n",
    "#         return (img ,label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_data_label(self,imgpath):\n",
    "\n",
    "        classes = self.get_classes()\n",
    "\n",
    "        seq = np.zeros((224, 224, 3, self.length), dtype=np.float32)\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "\n",
    "#         jitter = 0.2\n",
    "#         hue = 0.1\n",
    "#         saturation = 1.5 \n",
    "#         exposure = 1.5\n",
    "        jitter = 0\n",
    "        hue = 0\n",
    "        saturation = 0 \n",
    "        exposure = 0\n",
    "\n",
    "        img_path = imgpath.split(\" \")[0]\n",
    "        label_path = imgpath.split(\" \")[1]\n",
    "        label_index = int(classes.index(label_path))\n",
    "\n",
    "        video_length = len(os.listdir(img_path))\n",
    "        imgs = os.listdir(img_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        if video_length >= self.length:\n",
    "\n",
    "            select_frame = sorted(random.sample(range(video_length), self.length))\n",
    "            for m in range(self.length):\n",
    "                img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                #might need to remove data augmentation.\n",
    "                img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = data_augmentation(img, (224,224))\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "        else:\n",
    "            for k in range(self.length):\n",
    "                if k+1 <= video_length:\n",
    "                    img_file = os.path.join(img_path,imgs[k])\n",
    "                else:\n",
    "                    img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "                \n",
    "        data = np.transpose(seq, (3,2,0,1))\n",
    "        return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for line in open('/home/dua/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/classInd.txt'):\n",
    "    classes.append(line.strip().split()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.zeros((224, 224, 3, length), dtype=np.float32)\n",
    "\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "#         jitter = 0.2\n",
    "#         hue = 0.1\n",
    "#         saturation = 1.5 \n",
    "#         exposure = 1.5\n",
    "jitter = 0\n",
    "hue = 0\n",
    "saturation = 0 \n",
    "exposure = 0\n",
    "\n",
    "img_path = imgpath.split(\" \")[0]\n",
    "label_path = imgpath.split(\" \")[1]\n",
    "label_index = int(classes.index(label_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = len(os.listdir(img_path))\n",
    "imgs = os.listdir(img_path)\n",
    "imgs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_data_label(imgpath):\n",
    "\n",
    "        seq = np.zeros((224, 224, 3, length), dtype=np.float32)\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "\n",
    "#         jitter = 0.2\n",
    "#         hue = 0.1\n",
    "#         saturation = 1.5 \n",
    "#         exposure = 1.5\n",
    "        jitter = 0\n",
    "        hue = 0\n",
    "        saturation = 0 \n",
    "        exposure = 0\n",
    "\n",
    "        img_path = imgpath.split(\" \")[0]\n",
    "        label_path = imgpath.split(\" \")[1]\n",
    "        label_index = int(classes.index(label_path))\n",
    "\n",
    "        video_length = len(os.listdir(img_path))\n",
    "        imgs = os.listdir(img_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        if video_length >= length:\n",
    "\n",
    "            select_frame = sorted(random.sample(range(video_length), length))\n",
    "            for m in range(length):\n",
    "                img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                #might need to remove data augmentation.\n",
    "                img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = data_augmentation(img, (224,224))\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "        else:\n",
    "            for k in range(length):\n",
    "                if k+1 <= video_length:\n",
    "                    img_file = os.path.join(img_path,imgs[k])\n",
    "                else:\n",
    "                    img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "                \n",
    "        data = np.transpose(seq, (3,2,0,1))\n",
    "        return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ,label_index = load_data_label(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if video_length >= length:\n",
    "    print\n",
    "\n",
    "    select_frame = sorted(random.sample(range(video_length), self.length))\n",
    "    for m in range(self.length):\n",
    "        img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "        img =  Image.open(img_file).convert('RGB')\n",
    "        #might need to remove data augmentation.\n",
    "        img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = data_augmentation(img, (224,224))\n",
    "        img = np.array(img)\n",
    "\n",
    "        seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "        seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "        seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "else:\n",
    "    for k in range(length):\n",
    "        if k+1 <= video_length:\n",
    "            img_file = os.path.join(img_path,imgs[k])\n",
    "        else:\n",
    "            img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "        img =  Image.open(img_file).convert('RGB')\n",
    "        img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "        img = np.array(img)\n",
    "\n",
    "        seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "        seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "        seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "\n",
    "data = np.transpose(seq, (3,2,0,1))\n",
    "return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_test_data_label(self, imgpath, filter_size=16, stride=8):\n",
    "\n",
    "        data_transforms = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        classes = self.get_classes()\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "\n",
    "        img_path = imgpath.split(\" \")[0]\n",
    "        label_path = imgpath.split(\" \")[1]\n",
    "        label_index = int(classes.index(label_path))\n",
    "\n",
    "        video_length = len(os.listdir(img_path))\n",
    "        imgs = os.listdir(img_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        output = []\n",
    "        if video_length >= filter_size:\n",
    "            for i in range(0, video_length, stride):\n",
    "                if i + filter_size <= video_length:\n",
    "                    inputs = []\n",
    "                    frames_subset = imgs[i: i+filter_size]\n",
    "                    for frame in frames_subset:\n",
    "                        frame = os.path.join(img_path, frame)\n",
    "                        img = Image.open(frame)\n",
    "                        inputs.append(data_transforms(img).unsqueeze(0))\n",
    "                    output_subset = torch.cat(inputs).unsqueeze(0)\n",
    "                    output.append(output_subset)\n",
    "\n",
    "        else:\n",
    "            inputs = []\n",
    "            for k in range(filter_size):\n",
    "                if k+1 <= video_length:\n",
    "                    frame = os.path.join(img_path, imgs[k])\n",
    "                    img = Image.open(frame)\n",
    "                    inputs.append(data_transforms(img).unsqueeze(0))\n",
    "                else:\n",
    "                    frame = os.path.join(img_path, imgs[video_length-1])\n",
    "                    img = Image.open(frame)\n",
    "                    inputs.append(data_transforms(img).unsqueeze(0))\n",
    "            output_subset = torch.cat(inputs).unsqueeze(0)\n",
    "            output.append(output_subset)\n",
    "\n",
    "        output = torch.cat(output)\n",
    "\n",
    "        return output, label_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
