{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import numpy\n",
    "import dataset\n",
    "import random\n",
    "from utils import *\n",
    "from VGG_gru import FERANet\n",
    "# from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "import subprocess\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "description='PyTorch Facial Expression'\n",
    "batch_size = 1\n",
    "epochs = 20 #120\n",
    "length = 32\n",
    "preInitial = True\n",
    "# dataset = 'Emotiw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn= \"BDItrain1.txt\"\n",
    "vl= \"BDIval1.txt\"\n",
    "tst= \"BDItest1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+trn\n",
    "vallist =  \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+vl\n",
    "testlist =  \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/BDItrain1.txt\n"
     ]
    }
   ],
   "source": [
    "print(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_d= \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/dataset.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile != True:\n",
    "\tsubprocess.call([\"python\", path_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isfile != True:\n",
    "# \tsubprocess.call([\"python\", \"./TrainTestlist/\"+dataset+\"/getTraintest_\"+dataset+\".py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "backupdir     = \"/tmp/duaa/GRU\"\n",
    "batch_size    = 1\n",
    "# learning_rate = 0.00001\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# accuracy = 0.\n",
    "# best_accuracy = 0.\n",
    "metric = AccumulatedAccuracyMetric()\n",
    "\n",
    "####here for same result#####\n",
    "num_workers   = 0\n",
    "# torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "random.seed(1)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading vgg16 pre-fera2013 model...\n",
      "finish loading vgg16 pre-fera2013 model!\n"
     ]
    }
   ],
   "source": [
    "if preInitial == True:\n",
    "\tmodel = FERANet()\n",
    "\tmodel = Initial(model)\n",
    "else:\n",
    "\tmodel = FERANet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_batches = 0\n",
    "kwargs = {'num_workers': num_workers, 'pin_memory': True}\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate , momentum=0.9, weight_decay= 0.00005)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "use_Tensorboard = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,optimizer):\n",
    "\n",
    "\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset.listDataset(trainlist,length = length,\n",
    "\t\t\t\t\t   shuffle=True,\n",
    "\t\t\t\t\t   train=True,\n",
    "\t\t\t\t\t   dataset = dataset),\n",
    "\t\tbatch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor param_group in optimizer.param_groups:\n",
    "\t\ttrain_learning_rate = float(param_group['lr'])\n",
    "\n",
    "\tlogging('epoch %d, processed %d samples, lr %f' % (epoch, epoch * len(train_loader.dataset), train_learning_rate))\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\t\tdata = Variable(data).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.long()).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\toutput = model(data)\n",
    "\n",
    "\t\tloss = loss_function(output, label)\n",
    "\n",
    "\t\trunning_loss += loss.data\n",
    "\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\tif epoch %1 == 0:\n",
    "\t\tlogging('Loss:{:.6f}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch,metric):\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "# \tglobal best_accuracy\n",
    "# \tglobal accuracy\n",
    "\n",
    "\tmetric.reset()\n",
    "    \n",
    "\taccuracy = 0.\n",
    "\tbest_accuracy = 0.\n",
    "    \n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "# \t\tdataset.listDataset(vallist,length = length,\n",
    "\t\tdataset.listDataset(vallist,length = length,        \n",
    "\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\tdataset = dataset),\n",
    "\t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(test_loader):\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\n",
    "\t\tBatch,T,C,H,W = data.size()\n",
    "\n",
    "\t\tdata = Variable(data,volatile=True).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.long(),volatile=True).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "# \t\tprint('label')\n",
    "\t\toutput = []\n",
    "\t\tfor batch_index in range(Batch):\n",
    "# \t\t\tprint(batch_index)            \n",
    "\t\t\toutput_feature = model(data[batch_index])\n",
    "\n",
    "\t\t\toutput.append(output_feature)\n",
    "\n",
    "\t\toutput = torch.mean(torch.cat(output), 0, keepdim=True)\n",
    "        \n",
    "\n",
    "\t\tmetric(output, label) \n",
    "# \t\tprint(metric.value())\n",
    "\n",
    "\t\taccuracy, eval_loss = metric.value()\n",
    "# \t\tprint(accuracy)\n",
    "\n",
    "        \n",
    "\tif accuracy >= best_accuracy:\n",
    "\t\tbest_accuracy = accuracy\n",
    "\t\tprint(\"saving accuracy is: \",accuracy)\n",
    "\t\ttorch.save(model.state_dict(),'%s/model_%d.pkl' % (backupdir,epoch))\n",
    "\n",
    "\tlogging(\"test accuracy: %f\" % (accuracy))\n",
    "\tlogging(\"best accuracy: %f\" % (best_accuracy))\n",
    "\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,metric):\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "# \tglobal best_accuracy\n",
    "# \tglobal accuracy\n",
    "\n",
    "\tmetric.reset()\n",
    "    \n",
    "\taccuracy = 0.\n",
    "\tbest_accuracy = 0.\n",
    "    \n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "# \t\tdataset.listDataset(vallist,length = length,\n",
    "\t\tdataset.listDataset(testlist,length = length,        \n",
    "\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\tdataset = dataset),\n",
    "\t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(test_loader):\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\n",
    "\t\tBatch,T,C,H,W = data.size()\n",
    "\n",
    "\t\tdata = Variable(data,volatile=True).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.long(),volatile=True).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "# \t\tprint('label')\n",
    "\t\toutput = []\n",
    "\t\tfor batch_index in range(Batch):\n",
    "# \t\t\tprint(batch_index)            \n",
    "\t\t\toutput_feature = model(data[batch_index])\n",
    "\n",
    "\t\t\toutput.append(output_feature)\n",
    "\n",
    "\t\toutput = torch.mean(torch.cat(output), 0, keepdim=True)\n",
    "        \n",
    "\n",
    "\t\tmetric(output, label) \n",
    "# \t\tprint(metric.value())\n",
    "\n",
    "\t\taccuracy, eval_loss = metric.value()\n",
    "# \t\tprint(accuracy)\n",
    "\n",
    "        \n",
    "\tif accuracy >= best_accuracy:\n",
    "\t\tbest_accuracy = accuracy\n",
    "# \t\tprint(\"saving accuracy is: \",accuracy)\n",
    "# \t\ttorch.save(model.state_dict(),'%s/model_%d.pkl' % (backupdir,epoch))\n",
    "\n",
    "\tlogging(\"test accuracy: %f\" % (accuracy))\n",
    "\tlogging(\"best accuracy: %f\" % (best_accuracy))\n",
    "\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-11 04:39:25 epoch 1, processed 36 samples, lr 0.000100\n",
      "2021-01-11 04:39:38 Loss:25.107191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 04:42:24 test accuracy: 0.833333\n",
      "2021-01-11 04:42:24 best accuracy: 0.833333\n",
      "2021-01-11 04:42:24 epoch 2, processed 72 samples, lr 0.000100\n",
      "2021-01-11 04:42:35 Loss:21.700689\n",
      "saving accuracy is:  0.75\n",
      "2021-01-11 04:45:15 test accuracy: 0.750000\n",
      "2021-01-11 04:45:15 best accuracy: 0.750000\n",
      "2021-01-11 04:45:15 epoch 3, processed 108 samples, lr 0.000100\n",
      "2021-01-11 04:45:25 Loss:15.102221\n",
      "saving accuracy is:  0.6666666666666666\n",
      "2021-01-11 04:48:07 test accuracy: 0.666667\n",
      "2021-01-11 04:48:07 best accuracy: 0.666667\n",
      "2021-01-11 04:48:07 epoch 4, processed 144 samples, lr 0.000100\n",
      "2021-01-11 04:48:18 Loss:14.078545\n",
      "saving accuracy is:  0.75\n",
      "2021-01-11 04:51:00 test accuracy: 0.750000\n",
      "2021-01-11 04:51:00 best accuracy: 0.750000\n",
      "2021-01-11 04:51:00 epoch 5, processed 180 samples, lr 0.000100\n",
      "2021-01-11 04:51:10 Loss:10.164865\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 04:53:52 test accuracy: 0.916667\n",
      "2021-01-11 04:53:52 best accuracy: 0.916667\n",
      "2021-01-11 04:53:52 epoch 6, processed 216 samples, lr 0.000100\n",
      "2021-01-11 04:54:02 Loss:8.969983\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 04:56:45 test accuracy: 0.916667\n",
      "2021-01-11 04:56:45 best accuracy: 0.916667\n",
      "2021-01-11 04:56:45 epoch 7, processed 252 samples, lr 0.000100\n",
      "2021-01-11 04:56:56 Loss:7.541617\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 04:59:38 test accuracy: 0.916667\n",
      "2021-01-11 04:59:38 best accuracy: 0.916667\n",
      "2021-01-11 04:59:38 epoch 8, processed 288 samples, lr 0.000100\n",
      "2021-01-11 04:59:47 Loss:5.596052\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 05:02:30 test accuracy: 0.916667\n",
      "2021-01-11 05:02:30 best accuracy: 0.916667\n",
      "2021-01-11 05:02:30 epoch 9, processed 324 samples, lr 0.000100\n",
      "2021-01-11 05:02:41 Loss:3.522355\n",
      "saving accuracy is:  0.75\n",
      "2021-01-11 05:05:24 test accuracy: 0.750000\n",
      "2021-01-11 05:05:24 best accuracy: 0.750000\n",
      "2021-01-11 05:05:24 epoch 10, processed 360 samples, lr 0.000100\n",
      "2021-01-11 05:05:33 Loss:4.247070\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:08:16 test accuracy: 0.833333\n",
      "2021-01-11 05:08:16 best accuracy: 0.833333\n",
      "2021-01-11 05:08:16 epoch 11, processed 396 samples, lr 0.000100\n",
      "2021-01-11 05:08:26 Loss:1.907385\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:11:08 test accuracy: 0.833333\n",
      "2021-01-11 05:11:08 best accuracy: 0.833333\n",
      "2021-01-11 05:11:08 epoch 12, processed 432 samples, lr 0.000100\n",
      "2021-01-11 05:11:17 Loss:2.471475\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:14:01 test accuracy: 0.833333\n",
      "2021-01-11 05:14:01 best accuracy: 0.833333\n",
      "2021-01-11 05:14:01 epoch 13, processed 468 samples, lr 0.000100\n",
      "2021-01-11 05:14:11 Loss:1.674278\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:16:54 test accuracy: 0.833333\n",
      "2021-01-11 05:16:54 best accuracy: 0.833333\n",
      "2021-01-11 05:16:54 epoch 14, processed 504 samples, lr 0.000100\n",
      "2021-01-11 05:17:04 Loss:1.191200\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:19:46 test accuracy: 0.833333\n",
      "2021-01-11 05:19:46 best accuracy: 0.833333\n",
      "2021-01-11 05:19:46 epoch 15, processed 540 samples, lr 0.000100\n",
      "2021-01-11 05:19:56 Loss:1.047104\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 05:22:39 test accuracy: 0.916667\n",
      "2021-01-11 05:22:39 best accuracy: 0.916667\n",
      "2021-01-11 05:22:39 epoch 16, processed 576 samples, lr 0.000100\n",
      "2021-01-11 05:22:49 Loss:0.909282\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:25:31 test accuracy: 0.833333\n",
      "2021-01-11 05:25:31 best accuracy: 0.833333\n",
      "2021-01-11 05:25:31 epoch 17, processed 612 samples, lr 0.000100\n",
      "2021-01-11 05:25:41 Loss:1.041975\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 05:28:25 test accuracy: 0.916667\n",
      "2021-01-11 05:28:25 best accuracy: 0.916667\n",
      "2021-01-11 05:28:25 epoch 18, processed 648 samples, lr 0.000100\n",
      "2021-01-11 05:28:35 Loss:0.782335\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 05:31:18 test accuracy: 0.916667\n",
      "2021-01-11 05:31:18 best accuracy: 0.916667\n",
      "2021-01-11 05:31:18 epoch 19, processed 684 samples, lr 0.000100\n",
      "2021-01-11 05:31:28 Loss:0.743185\n",
      "saving accuracy is:  0.9166666666666666\n",
      "2021-01-11 05:34:10 test accuracy: 0.916667\n",
      "2021-01-11 05:34:10 best accuracy: 0.916667\n",
      "2021-01-11 05:34:10 epoch 20, processed 720 samples, lr 0.000100\n",
      "2021-01-11 05:34:20 Loss:0.740265\n",
      "saving accuracy is:  0.8333333333333334\n",
      "2021-01-11 05:37:03 test accuracy: 0.833333\n",
      "2021-01-11 05:37:03 best accuracy: 0.833333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1): \n",
    "\n",
    "\ttrain(epoch,optimizer)\n",
    "\twith torch.no_grad():\n",
    "\t\teval_accuary = eval(epoch,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-11 05:39:55 test accuracy: 1.000000\n",
      "2021-01-11 05:39:55 best accuracy: 1.000000\n",
      "2021-01-11 05:42:45 test accuracy: 1.000000\n",
      "2021-01-11 05:42:45 best accuracy: 1.000000\n",
      "2021-01-11 05:45:36 test accuracy: 1.000000\n",
      "2021-01-11 05:45:36 best accuracy: 1.000000\n",
      "2021-01-11 05:48:26 test accuracy: 1.000000\n",
      "2021-01-11 05:48:26 best accuracy: 1.000000\n",
      "2021-01-11 05:51:17 test accuracy: 1.000000\n",
      "2021-01-11 05:51:17 best accuracy: 1.000000\n",
      "2021-01-11 05:54:08 test accuracy: 1.000000\n",
      "2021-01-11 05:54:08 best accuracy: 1.000000\n",
      "2021-01-11 05:56:57 test accuracy: 1.000000\n",
      "2021-01-11 05:56:57 best accuracy: 1.000000\n",
      "2021-01-11 05:59:47 test accuracy: 1.000000\n",
      "2021-01-11 05:59:47 best accuracy: 1.000000\n",
      "2021-01-11 06:02:36 test accuracy: 1.000000\n",
      "2021-01-11 06:02:36 best accuracy: 1.000000\n",
      "2021-01-11 06:05:26 test accuracy: 1.000000\n",
      "2021-01-11 06:05:26 best accuracy: 1.000000\n",
      "2021-01-11 06:08:17 test accuracy: 1.000000\n",
      "2021-01-11 06:08:17 best accuracy: 1.000000\n",
      "2021-01-11 06:11:06 test accuracy: 1.000000\n",
      "2021-01-11 06:11:06 best accuracy: 1.000000\n",
      "2021-01-11 06:13:56 test accuracy: 1.000000\n",
      "2021-01-11 06:13:56 best accuracy: 1.000000\n",
      "2021-01-11 06:16:45 test accuracy: 1.000000\n",
      "2021-01-11 06:16:45 best accuracy: 1.000000\n",
      "2021-01-11 06:19:34 test accuracy: 1.000000\n",
      "2021-01-11 06:19:34 best accuracy: 1.000000\n",
      "2021-01-11 06:22:24 test accuracy: 1.000000\n",
      "2021-01-11 06:22:24 best accuracy: 1.000000\n",
      "2021-01-11 06:25:14 test accuracy: 1.000000\n",
      "2021-01-11 06:25:14 best accuracy: 1.000000\n",
      "2021-01-11 06:28:05 test accuracy: 1.000000\n",
      "2021-01-11 06:28:05 best accuracy: 1.000000\n",
      "2021-01-11 06:30:53 test accuracy: 1.000000\n",
      "2021-01-11 06:30:53 best accuracy: 1.000000\n",
      "2021-01-11 06:33:44 test accuracy: 1.000000\n",
      "2021-01-11 06:33:44 best accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1): \n",
    "\twith torch.no_grad():\n",
    "\t\teval_accuary = test(epoch,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
