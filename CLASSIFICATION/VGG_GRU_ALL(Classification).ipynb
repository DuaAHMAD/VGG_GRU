{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import numpy\n",
    "import dataset\n",
    "import dataset_test\n",
    "import random\n",
    "from utils import *\n",
    "from VGG_gru import FERANet\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "import subprocess\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading VGG-Face model...\n",
      "finish loading VGG-Face model!\n"
     ]
    }
   ],
   "source": [
    "# model can be downloaded here: https://drive.google.com/drive/folders/1f17xgwvGaUpgXYBssocUNXDBgga-b3qp\n",
    "preInitial = False\n",
    "if preInitial == True:\n",
    "\tmodel = FERANet()\n",
    "\tmodel = Initial(model)\n",
    "else:\n",
    "\tmodel = FERANet()\n",
    "\tmodel = VGG_Initial(model)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate , momentum=0.9, weight_decay= 0.00005)\n",
    "#https://discuss.pytorch.org/t/problem-about-k-fold-validation/32334/2    \n",
    "init_state = copy.deepcopy(model.state_dict())\n",
    "init_state_opt = copy.deepcopy(optimizer.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_batches = 0\n",
    "num_workers   = 0\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "random.seed(1)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "kwargs = {'num_workers': num_workers, 'pin_memory': True}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL PARAMETERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# learning_rate = 0.0001\n",
    "epochs = 20 \n",
    "length = 32\n",
    "\n",
    "use_Tensorboard = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO CHANGE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TO CHANGE #######\n",
    "# EXP_TYPE = 'Regression/'\n",
    "EXP_TYPE = 'Classification/'\n",
    "\n",
    "#### Change loss function in UTILS.py\n",
    "\n",
    "metric = AccumulatedAccuracyMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO KEEP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,optimizer):\n",
    "      \n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset.listDataset(trainlist,length = length,\n",
    "\t\t\t\t\t   shuffle=True,\n",
    "\t\t\t\t\t   train=True,\n",
    "\t\t\t\t\t   dataset = dataset),\n",
    "\t\tbatch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor param_group in optimizer.param_groups:\n",
    "\t\ttrain_learning_rate = float(param_group['lr'])\n",
    "\n",
    "\tlogging('epoch %d, processed %d samples, lr %f' % (epoch, epoch * len(train_loader.dataset), train_learning_rate))\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\t\tdata = Variable(data).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.long()).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "        \n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\toutput = model(data)\n",
    "\n",
    "\t\tloss = loss_function(output, label)\n",
    "\n",
    "\t\trunning_loss += loss.data\n",
    "\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\tif epoch %1 == 0:\n",
    "\t\tlogging('Train Loss:{:.6f}'.format(running_loss))\n",
    "        \n",
    "\treturn running_loss        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch,metric):\n",
    "\n",
    "\tmodel.eval()\n",
    "    \n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset.listDataset(vallist,length = length,       \n",
    "\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\tdataset = dataset),\n",
    "\t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(test_loader):\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\t\tBatch,T,C,H,W = data.size()\n",
    "\n",
    "\t\tdata = Variable(data,volatile=True).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.long(),volatile=True).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "\t\toutput = []\n",
    "        \n",
    "\t\tfor batch_index in range(Batch):\n",
    "# \t\t\tprint(batch_index) \n",
    "# \t\t\twith torch.no_grad():\n",
    "\t\t\toutput_feature = model(data[batch_index])\n",
    "\t\t\toutput.append(output_feature)\n",
    "\t\toutput = torch.mean(torch.cat(output), 0, keepdim=True) \n",
    "# \t\tprint(\"Dua's output is: \", output)\n",
    "# \t\twith torch.no_grad():\n",
    "\t\tmetric(output, label) \n",
    "\t\teval_loss = metric.value()\n",
    "\tif epoch %1 == 0:\n",
    "\t\tlogging(\"Eval Loss: %f\" % (eval_loss))\n",
    "    \n",
    "\treturn eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,metric):\n",
    "    \n",
    "\tmodel.eval()\n",
    "\tresult = []    \n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset_test.listTESTDataset(testlist,length = length,\n",
    "# \t\tdataset.listDataset(vallist,length = length,        \n",
    "\t\t\t\t\tshuffle=False,\n",
    "# \t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\tdataset = dataset),\n",
    "\t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "    \n",
    "\tfor batch_idx, (data, label, participant) in enumerate(test_loader):\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\n",
    "\t\tBatch,T,C,H,W = data.size()\n",
    "\t\tdata = Variable(data,volatile=True).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.long(),volatile=True).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "# \t\tprint('Participant name:',participant)\n",
    "# \t\tprint('Participant label:',int(label))\n",
    "\t\toutput = []\n",
    "\t\tfor batch_index in range(Batch):           \n",
    "\t\t\toutput_feature = model(data[batch_index])\n",
    "\t\t\toutput.append(output_feature)\n",
    "\t\toutput = torch.mean(torch.cat(output), 0, keepdim=True)      \n",
    "# \t\tprint(\"Participant output is: \", output)\n",
    "\t\tmetric(output, label) \n",
    "\t\ttest_loss = metric.value()\n",
    "# \t\tprint(\"Participant loss is: \", test_loss)\n",
    "\t\tresult.append([participant, int(label), output, test_loss])\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMB = ['BDI','AVEC','AVEC-BDI','AVEC-TEST','BDI-TEST']\n",
    "NUM = ['1','2','3','4','5']\n",
    "#Text file of image path for each of the above combinations\n",
    "textMAIN = '/timo/datasets/Dua/GRU-test/Data-Combinations/'\n",
    "textPATH = textMAIN+EXP_TYPE\n",
    "backupdir     = '/timo/datasets/Dua/GRU-test/Saved-Models'\n",
    "results_PATH = '/timo/datasets/Dua/GRU-test/Results/'\n",
    "#Datasets Path (participants Path) AVEC + BDI\n",
    "# path_d= '/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/dataset.py'\n",
    "#Where to save trained models Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isfile != True:\n",
    "# \tsubprocess.call([\"python\", path_d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training+Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-02 07:49:15 epoch 1, processed 36 samples, lr 0.000100\n",
      "2021-03-02 07:49:26 Train Loss:26.669254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-02 07:52:14 Eval Loss: 7.546226\n",
      "2021-03-02 07:52:14 epoch 2, processed 72 samples, lr 0.000100\n",
      "2021-03-02 07:52:25 Train Loss:23.759930\n",
      "2021-03-02 07:55:11 Eval Loss: 14.874059\n",
      "2021-03-02 07:55:11 epoch 3, processed 108 samples, lr 0.000100\n",
      "2021-03-02 07:55:22 Train Loss:21.099333\n",
      "2021-03-02 07:58:06 Eval Loss: 21.844591\n",
      "2021-03-02 07:58:06 epoch 4, processed 144 samples, lr 0.000100\n",
      "2021-03-02 07:58:17 Train Loss:20.209955\n",
      "2021-03-02 08:01:00 Eval Loss: 28.441851\n",
      "2021-03-02 08:01:00 epoch 5, processed 180 samples, lr 0.000100\n",
      "2021-03-02 08:01:10 Train Loss:16.165459\n",
      "2021-03-02 08:03:52 Eval Loss: 37.737408\n",
      "2021-03-02 08:03:52 epoch 6, processed 216 samples, lr 0.000100\n",
      "2021-03-02 08:04:02 Train Loss:16.196770\n",
      "2021-03-02 08:06:44 Eval Loss: 44.149010\n",
      "2021-03-02 08:06:44 epoch 7, processed 252 samples, lr 0.000100\n",
      "2021-03-02 08:06:55 Train Loss:12.583697\n",
      "2021-03-02 08:09:36 Eval Loss: 53.645378\n",
      "2021-03-02 08:09:36 epoch 8, processed 288 samples, lr 0.000100\n",
      "2021-03-02 08:09:47 Train Loss:13.021741\n",
      "2021-03-02 08:12:30 Eval Loss: 60.172558\n",
      "2021-03-02 08:12:30 epoch 9, processed 324 samples, lr 0.000100\n",
      "2021-03-02 08:12:41 Train Loss:7.414155\n",
      "2021-03-02 08:15:24 Eval Loss: 68.624985\n",
      "2021-03-02 08:15:24 epoch 10, processed 360 samples, lr 0.000100\n",
      "2021-03-02 08:15:34 Train Loss:5.796307\n",
      "2021-03-02 08:18:18 Eval Loss: 77.142021\n",
      "2021-03-02 08:18:18 epoch 11, processed 396 samples, lr 0.000100\n",
      "2021-03-02 08:18:28 Train Loss:5.052173\n",
      "2021-03-02 08:21:08 Eval Loss: 82.873520\n",
      "2021-03-02 08:21:08 epoch 12, processed 432 samples, lr 0.000100\n",
      "2021-03-02 08:21:20 Train Loss:3.176365\n",
      "2021-03-02 08:24:01 Eval Loss: 91.261414\n",
      "2021-03-02 08:24:01 epoch 13, processed 468 samples, lr 0.000100\n",
      "2021-03-02 08:24:11 Train Loss:7.614342\n",
      "2021-03-02 08:26:55 Eval Loss: 100.534256\n",
      "2021-03-02 08:26:55 epoch 14, processed 504 samples, lr 0.000100\n",
      "2021-03-02 08:27:06 Train Loss:6.061852\n",
      "2021-03-02 08:29:48 Eval Loss: 110.120605\n",
      "2021-03-02 08:29:48 epoch 15, processed 540 samples, lr 0.000100\n",
      "2021-03-02 08:29:59 Train Loss:2.934150\n",
      "2021-03-02 08:32:42 Eval Loss: 118.188469\n",
      "2021-03-02 08:32:42 epoch 16, processed 576 samples, lr 0.000100\n",
      "2021-03-02 08:32:52 Train Loss:1.536854\n",
      "2021-03-02 08:35:36 Eval Loss: 126.054451\n",
      "2021-03-02 08:35:36 epoch 17, processed 612 samples, lr 0.000100\n",
      "2021-03-02 08:35:46 Train Loss:1.147532\n",
      "2021-03-02 08:38:30 Eval Loss: 134.286118\n",
      "2021-03-02 08:38:30 epoch 18, processed 648 samples, lr 0.000100\n",
      "2021-03-02 08:38:42 Train Loss:0.811571\n",
      "2021-03-02 08:41:27 Eval Loss: 143.201141\n",
      "2021-03-02 08:41:27 epoch 19, processed 684 samples, lr 0.000100\n",
      "2021-03-02 08:41:38 Train Loss:0.766309\n",
      "2021-03-02 08:44:19 Eval Loss: 151.938278\n",
      "2021-03-02 08:44:19 epoch 20, processed 720 samples, lr 0.000100\n",
      "2021-03-02 08:44:30 Train Loss:0.653712\n",
      "2021-03-02 08:47:11 Eval Loss: 161.540970\n",
      "2021-03-02 08:47:16 epoch 1, processed 36 samples, lr 0.000100\n",
      "2021-03-02 08:47:27 Train Loss:26.209898\n",
      "2021-03-02 08:50:16 Eval Loss: 169.478775\n",
      "2021-03-02 08:50:16 epoch 2, processed 72 samples, lr 0.000100\n",
      "2021-03-02 08:50:26 Train Loss:23.676086\n",
      "2021-03-02 08:53:17 Eval Loss: 176.616501\n",
      "2021-03-02 08:53:17 epoch 3, processed 108 samples, lr 0.000100\n",
      "2021-03-02 08:53:26 Train Loss:21.934063\n",
      "2021-03-02 08:56:15 Eval Loss: 182.903122\n",
      "2021-03-02 08:56:15 epoch 4, processed 144 samples, lr 0.000100\n",
      "2021-03-02 08:56:25 Train Loss:18.681902\n",
      "2021-03-02 08:59:16 Eval Loss: 188.283630\n",
      "2021-03-02 08:59:16 epoch 5, processed 180 samples, lr 0.000100\n",
      "2021-03-02 08:59:26 Train Loss:17.615358\n",
      "2021-03-02 09:02:17 Eval Loss: 196.456512\n",
      "2021-03-02 09:02:17 epoch 6, processed 216 samples, lr 0.000100\n",
      "2021-03-02 09:02:29 Train Loss:18.095787\n",
      "2021-03-02 09:05:17 Eval Loss: 202.543274\n",
      "2021-03-02 09:05:17 epoch 7, processed 252 samples, lr 0.000100\n",
      "2021-03-02 09:05:28 Train Loss:14.719646\n",
      "2021-03-02 09:08:22 Eval Loss: 206.272598\n",
      "2021-03-02 09:08:22 epoch 8, processed 288 samples, lr 0.000100\n",
      "2021-03-02 09:08:33 Train Loss:10.097440\n",
      "2021-03-02 09:11:23 Eval Loss: 208.943588\n",
      "2021-03-02 09:11:23 epoch 9, processed 324 samples, lr 0.000100\n",
      "2021-03-02 09:11:34 Train Loss:9.694478\n",
      "2021-03-02 09:14:25 Eval Loss: 211.788589\n",
      "2021-03-02 09:14:25 epoch 10, processed 360 samples, lr 0.000100\n",
      "2021-03-02 09:14:35 Train Loss:5.809690\n",
      "2021-03-02 09:17:24 Eval Loss: 213.658920\n",
      "2021-03-02 09:17:24 epoch 11, processed 396 samples, lr 0.000100\n",
      "2021-03-02 09:17:35 Train Loss:4.414028\n",
      "2021-03-02 09:20:26 Eval Loss: 215.157318\n",
      "2021-03-02 09:20:26 epoch 12, processed 432 samples, lr 0.000100\n",
      "2021-03-02 09:20:35 Train Loss:5.211947\n",
      "2021-03-02 09:23:24 Eval Loss: 216.579163\n",
      "2021-03-02 09:23:24 epoch 13, processed 468 samples, lr 0.000100\n",
      "2021-03-02 09:23:36 Train Loss:3.116210\n",
      "2021-03-02 09:26:34 Eval Loss: 218.353531\n",
      "2021-03-02 09:26:34 epoch 14, processed 504 samples, lr 0.000100\n",
      "2021-03-02 09:26:49 Train Loss:2.756172\n",
      "2021-03-02 09:29:56 Eval Loss: 219.401947\n",
      "2021-03-02 09:29:56 epoch 15, processed 540 samples, lr 0.000100\n",
      "2021-03-02 09:30:07 Train Loss:2.175423\n",
      "2021-03-02 09:32:56 Eval Loss: 221.242783\n",
      "2021-03-02 09:32:56 epoch 16, processed 576 samples, lr 0.000100\n",
      "2021-03-02 09:33:07 Train Loss:1.660147\n",
      "2021-03-02 09:35:59 Eval Loss: 222.260162\n",
      "2021-03-02 09:35:59 epoch 17, processed 612 samples, lr 0.000100\n",
      "2021-03-02 09:36:10 Train Loss:0.915823\n",
      "2021-03-02 09:38:59 Eval Loss: 223.204758\n",
      "2021-03-02 09:38:59 epoch 18, processed 648 samples, lr 0.000100\n",
      "2021-03-02 09:39:10 Train Loss:1.182521\n",
      "2021-03-02 09:42:03 Eval Loss: 224.307709\n",
      "2021-03-02 09:42:03 epoch 19, processed 684 samples, lr 0.000100\n",
      "2021-03-02 09:42:12 Train Loss:0.786900\n",
      "2021-03-02 09:45:03 Eval Loss: 225.173599\n",
      "2021-03-02 09:45:04 epoch 20, processed 720 samples, lr 0.000100\n",
      "2021-03-02 09:45:15 Train Loss:0.595913\n",
      "2021-03-02 09:48:09 Eval Loss: 226.030365\n",
      "2021-03-02 09:48:14 epoch 1, processed 36 samples, lr 0.000100\n",
      "2021-03-02 09:48:26 Train Loss:25.604946\n",
      "2021-03-02 09:51:17 Eval Loss: 233.871582\n",
      "2021-03-02 09:51:18 epoch 2, processed 72 samples, lr 0.000100\n",
      "2021-03-02 09:51:27 Train Loss:22.930080\n",
      "2021-03-02 09:54:21 Eval Loss: 240.909607\n",
      "2021-03-02 09:54:21 epoch 3, processed 108 samples, lr 0.000100\n",
      "2021-03-02 09:54:31 Train Loss:19.907869\n",
      "2021-03-02 09:57:24 Eval Loss: 247.090164\n",
      "2021-03-02 09:57:24 epoch 4, processed 144 samples, lr 0.000100\n",
      "2021-03-02 09:57:35 Train Loss:17.848314\n",
      "2021-03-02 10:00:27 Eval Loss: 252.928772\n",
      "2021-03-02 10:00:27 epoch 5, processed 180 samples, lr 0.000100\n",
      "2021-03-02 10:00:38 Train Loss:20.733067\n",
      "2021-03-02 10:03:28 Eval Loss: 259.135590\n",
      "2021-03-02 10:03:28 epoch 6, processed 216 samples, lr 0.000100\n",
      "2021-03-02 10:03:38 Train Loss:14.629375\n",
      "2021-03-02 10:06:32 Eval Loss: 264.331329\n",
      "2021-03-02 10:06:32 epoch 7, processed 252 samples, lr 0.000100\n",
      "2021-03-02 10:06:42 Train Loss:12.430893\n",
      "2021-03-02 10:09:33 Eval Loss: 269.257080\n",
      "2021-03-02 10:09:33 epoch 8, processed 288 samples, lr 0.000100\n",
      "2021-03-02 10:09:43 Train Loss:9.204973\n",
      "2021-03-02 10:12:36 Eval Loss: 273.235352\n",
      "2021-03-02 10:12:36 epoch 9, processed 324 samples, lr 0.000100\n",
      "2021-03-02 10:12:47 Train Loss:7.135195\n",
      "2021-03-02 10:15:41 Eval Loss: 276.280396\n",
      "2021-03-02 10:15:41 epoch 10, processed 360 samples, lr 0.000100\n",
      "2021-03-02 10:15:51 Train Loss:4.769425\n",
      "2021-03-02 10:18:42 Eval Loss: 279.956970\n",
      "2021-03-02 10:18:42 epoch 11, processed 396 samples, lr 0.000100\n",
      "2021-03-02 10:18:53 Train Loss:5.329394\n",
      "2021-03-02 10:21:42 Eval Loss: 285.591400\n",
      "2021-03-02 10:21:42 epoch 12, processed 432 samples, lr 0.000100\n",
      "2021-03-02 10:21:52 Train Loss:2.706160\n",
      "2021-03-02 10:24:43 Eval Loss: 287.958405\n",
      "2021-03-02 10:24:43 epoch 13, processed 468 samples, lr 0.000100\n",
      "2021-03-02 10:24:54 Train Loss:2.231996\n",
      "2021-03-02 10:27:45 Eval Loss: 290.129120\n",
      "2021-03-02 10:27:45 epoch 14, processed 504 samples, lr 0.000100\n",
      "2021-03-02 10:27:57 Train Loss:1.793398\n",
      "2021-03-02 10:30:48 Eval Loss: 292.337189\n",
      "2021-03-02 10:30:48 epoch 15, processed 540 samples, lr 0.000100\n",
      "2021-03-02 10:30:58 Train Loss:1.676451\n",
      "2021-03-02 10:33:49 Eval Loss: 294.150970\n",
      "2021-03-02 10:33:49 epoch 16, processed 576 samples, lr 0.000100\n",
      "2021-03-02 10:33:58 Train Loss:0.917966\n",
      "2021-03-02 10:36:46 Eval Loss: 295.904266\n",
      "2021-03-02 10:36:46 epoch 17, processed 612 samples, lr 0.000100\n",
      "2021-03-02 10:36:58 Train Loss:0.932920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-11da6d821c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtrain_val_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtrn_tensor_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cfececf7a136>\u001b[0m in \u001b[0;36meval\u001b[0;34m(epoch, metric)\u001b[0m\n\u001b[1;32m     10\u001b[0m \t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GRU-test/emotion_classification-master/VGG_GRU/CLASSIFICATION/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_test_data_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;31m# img   = torch.from_numpy(img).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GRU-test/emotion_classification-master/VGG_GRU/CLASSIFICATION/dataset.py\u001b[0m in \u001b[0;36mload_test_data_label\u001b[0;34m(self, imgpath, filter_size, stride)\u001b[0m\n\u001b[1;32m    138\u001b[0m                         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0moutput_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_tensor_writer = SummaryWriter()\n",
    "val_tensor_writer = SummaryWriter()\n",
    "for C in COMB:\n",
    "    for N in NUM:\n",
    "        model.load_state_dict(init_state)\n",
    "        model = model.cuda()\n",
    "        optimizer.load_state_dict(init_state_opt)\n",
    "        train_val_loss = []\n",
    "        trainlist=textPATH+C+'train'+N+'.txt'\n",
    "        vallist=textPATH+C+'val'+N+'.txt'\n",
    "        for epoch in range(1, epochs+1): \n",
    "            train_loss = train(epoch,optimizer)\n",
    "            with torch.no_grad():\n",
    "                eval_loss = eval(epoch,metric)\n",
    "            train_val_loss.append([int(train_loss), int(eval_loss)]) \n",
    "            trn_tensor_writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            val_tensor_writer.add_scalar(\"Loss/val\", eval_loss, epoch)\n",
    "        with open(results_PATH+C+'train_val'+N+'_loss.csv', 'w') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerows(train_val_loss)\n",
    "        trn_tensor_writer.flush()\n",
    "        val_tensor_writer.flush()\n",
    "        csvFile.close()\n",
    "        torch.save(model.state_dict(),'%s/model_%s%s.pkl' % (backupdir,C,N))\n",
    "trn_tensor_writer.close()\n",
    "val_tensor_writer.close()\n",
    "\n",
    "        #add saving train +eval loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in COMB:\n",
    "    for N in NUM:\n",
    "        testlist=textPATH+C+'test'+N+'.txt'\n",
    "        model.load_state_dict(torch.load('%s/model_%s%s.pkl' % (backupdir,C,N)))\n",
    "        with torch.no_grad():\n",
    "            test_accuary = test(epoch,metric)\n",
    "        with open(results_PATH+C+'test'+N+'Results.csv', 'w') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerows(test_accuary)\n",
    "        csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/timo/datasets/Dua/GRU-test/Results/test.csv')\n",
    "# data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
