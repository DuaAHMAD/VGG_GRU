{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import numpy\n",
    "import dataset\n",
    "import random\n",
    "from utils import *\n",
    "from VGG_gru import FERANet\n",
    "# from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "import subprocess\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "description='PyTorch Facial Expression'\n",
    "batch_size = 1\n",
    "epochs = 20 #120\n",
    "length = 32\n",
    "preInitial = True\n",
    "# dataset = 'Emotiw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn= \"BDItrain1.txt\"\n",
    "vl= \"BDIval1.txt\"\n",
    "tst= \"BDItest1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+trn\n",
    "vallist =  \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+vl\n",
    "testlist =  \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/BDItrain1.txt\n"
     ]
    }
   ],
   "source": [
    "print(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_d= \"/home/duaa/Desktop/GRU-test/emotion_classification-master/VGG_GRU/dataset.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile != True:\n",
    "\tsubprocess.call([\"python\", path_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isfile != True:\n",
    "# \tsubprocess.call([\"python\", \"./TrainTestlist/\"+dataset+\"/getTraintest_\"+dataset+\".py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "backupdir     = \"/tmp/duaa/GRU\"\n",
    "batch_size    = 1\n",
    "# learning_rate = 0.00001\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# accuracy = 0.\n",
    "# best_accuracy = 0.\n",
    "# metric = AccumulatedAccuracyMetric()\n",
    "metric = RegressionMetric()\n",
    "\n",
    "####here for same result#####\n",
    "num_workers   = 0\n",
    "# torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "random.seed(1)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading vgg16 pre-fera2013 model...\n",
      "finish loading vgg16 pre-fera2013 model!\n"
     ]
    }
   ],
   "source": [
    "if preInitial == True:\n",
    "\tmodel = FERANet()\n",
    "\tmodel = Initial(model)\n",
    "else:\n",
    "\tmodel = FERANet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_batches = 0\n",
    "kwargs = {'num_workers': num_workers, 'pin_memory': True}\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate , momentum=0.9, weight_decay= 0.00005)\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.L1Loss()\n",
    "# loss_function = nn.MSELoss()\n",
    "\n",
    "use_Tensorboard = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,optimizer):\n",
    "\n",
    "\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset.listDataset(trainlist,length = length,\n",
    "\t\t\t\t\t   shuffle=True,\n",
    "\t\t\t\t\t   train=True,\n",
    "\t\t\t\t\t   dataset = dataset),\n",
    "\t\tbatch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor param_group in optimizer.param_groups:\n",
    "\t\ttrain_learning_rate = float(param_group['lr'])\n",
    "\n",
    "\tlogging('epoch %d, processed %d samples, lr %f' % (epoch, epoch * len(train_loader.dataset), train_learning_rate))\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\t\tdata = Variable(data).cuda()\n",
    "\n",
    "# \t\tlabel = Variable(label.long()).cuda()\n",
    "\t\tlabel = Variable(label.float()).cuda()\n",
    "# \t\tlabel = label.squeeze(1)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\toutput = model(data)\n",
    "\n",
    "\t\tloss = loss_function(output, label)\n",
    "\n",
    "\t\trunning_loss += loss.data\n",
    "\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\tif epoch %1 == 0:\n",
    "\t\tlogging('Train Loss:{:.6f}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ttest_loader = torch.utils.data.DataLoader(\n",
    "# \t\tdataset.listDataset(vallist,length = length,\n",
    "# # \t\tdataset.listDataset(vallist,length = length,        \n",
    "# \t\t\t\t\tshuffle=False,\n",
    "# \t\t\t\t\ttrain=False,\n",
    "# \t\t\t\t\tdataset = dataset),\n",
    "# \t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch,metric):\n",
    "\n",
    "\tmodel.eval()\n",
    "    \n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset.listDataset(vallist,length = length,\n",
    "# \t\tdataset.listDataset(vallist,length = length,        \n",
    "\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\tdataset = dataset),\n",
    "\t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(test_loader):\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\n",
    "\t\tBatch,T,C,H,W = data.size()\n",
    "\n",
    "\t\tdata = Variable(data,volatile=True).cuda()\n",
    "\n",
    "\t\tlabel = Variable(label.float(),volatile=True).cuda()\n",
    "# \t\tlabel = Variable(label.long(),volatile=True).cuda()        \n",
    "# \t\tlabel = label.squeeze(1)\n",
    "# \t\tprint('label')\n",
    "\t\toutput = []\n",
    "\t\tfor batch_index in range(Batch):\n",
    "# \t\t\tprint(batch_index)            \n",
    "\t\t\toutput_feature = model(data[batch_index])\n",
    "\n",
    "\t\t\toutput.append(output_feature)\n",
    "\n",
    "\t\toutput = torch.mean(torch.cat(output), 0, keepdim=True)\n",
    "        \n",
    "# \t\tprint(\"Dua's output is: \", output)\n",
    "\t\tmetric(output, label) \n",
    "\t\teval_loss = metric.value()\n",
    "# # \t\tprint(metric.value())\n",
    "\n",
    "# \t\taccuracy, eval_loss = metric.value()\n",
    "# # \t\tprint(\"Dua's test is: \",accuracy)\n",
    "\n",
    "        \n",
    "# \tif accuracy >= best_accuracy:\n",
    "# \t\tbest_accuracy = accuracy\n",
    "# \t\tprint(\"saving accuracy is: \",accuracy)\n",
    "# \t\ttorch.save(model.state_dict(),'%s/model_%d.pkl' % (backupdir,epoch))\n",
    "\tif epoch %1 == 0:\n",
    "\t\tlogging(\"Eval Loss: %f\" % (eval_loss))\n",
    "    \n",
    "# \tlogging(\"test accuracy: %f\" % (accuracy))\n",
    "# \tlogging(\"best accuracy: %f\" % (best_accuracy))\n",
    "\n",
    "# \treturn eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,metric):\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "# \tglobal best_accuracy\n",
    "# \tglobal accuracy\n",
    "\n",
    "\tmetric.reset()\n",
    "    \n",
    "\taccuracy = 0.\n",
    "\tbest_accuracy = 0.\n",
    "    \n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset.listDataset(testlist,length = length,        \n",
    "\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\tdataset = dataset),\n",
    "\t\t\t\t\tbatch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\tfor batch_idx, (data, label) in enumerate(test_loader):\n",
    "\n",
    "\t\tdata = data.squeeze(0)\n",
    "\n",
    "\t\tBatch,T,C,H,W = data.size()\n",
    "\n",
    "\t\tdata = Variable(data,volatile=True).cuda()\n",
    "\n",
    "# \t\tlabel = Variable(label.long(),volatile=True).cuda()\n",
    "\t\tlabel = Variable(label.float(),volatile=True).cuda()\n",
    "\t\tlabel = label.squeeze(1)\n",
    "# \t\tprint('label')\n",
    "\t\toutput = []\n",
    "\t\tfor batch_index in range(Batch):\n",
    "# \t\t\tprint(batch_index)            \n",
    "\t\t\toutput_feature = model(data[batch_index])\n",
    "\n",
    "\t\t\toutput.append(output_feature)\n",
    "\n",
    "\t\toutput = torch.mean(torch.cat(output), 0, keepdim=True)\n",
    "        \n",
    "\n",
    "# \t\tmetric(output, label) \n",
    "# # \t\tprint(metric.value())\n",
    "\n",
    "# \t\taccuracy, eval_loss = metric.value()\n",
    "# # \t\tprint(accuracy)\n",
    "\n",
    "        \n",
    "# \tif accuracy >= best_accuracy:\n",
    "# \t\tbest_accuracy = accuracy\n",
    "# # \t\tprint(\"saving accuracy is: \",accuracy)\n",
    "# # \t\ttorch.save(model.state_dict(),'%s/model_%d.pkl' % (backupdir,epoch))\n",
    "\n",
    "# \tlogging(\"test accuracy: %f\" % (accuracy))\n",
    "# \tlogging(\"best accuracy: %f\" % (best_accuracy))\n",
    "\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-08 02:38:13 epoch 1, processed 36 samples, lr 0.000100\n",
      "2021-02-08 02:38:26 Train Loss:338.817474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-08 02:41:18 Eval Loss: 113.439445\n",
      "2021-02-08 02:41:18 epoch 2, processed 72 samples, lr 0.000100\n",
      "2021-02-08 02:41:29 Train Loss:335.009094\n",
      "2021-02-08 02:44:17 Eval Loss: 226.296997\n",
      "2021-02-08 02:44:17 epoch 3, processed 108 samples, lr 0.000100\n",
      "2021-02-08 02:44:28 Train Loss:327.431091\n",
      "2021-02-08 02:47:17 Eval Loss: 338.370636\n",
      "2021-02-08 02:47:17 epoch 4, processed 144 samples, lr 0.000100\n",
      "2021-02-08 02:47:27 Train Loss:319.656555\n",
      "2021-02-08 02:50:16 Eval Loss: 449.360596\n",
      "2021-02-08 02:50:16 epoch 5, processed 180 samples, lr 0.000100\n",
      "2021-02-08 02:50:26 Train Loss:317.020386\n",
      "2021-02-08 02:53:13 Eval Loss: 559.303162\n",
      "2021-02-08 02:53:13 epoch 6, processed 216 samples, lr 0.000100\n",
      "2021-02-08 02:53:22 Train Loss:310.052246\n",
      "2021-02-08 02:56:09 Eval Loss: 668.582947\n",
      "2021-02-08 02:56:09 epoch 7, processed 252 samples, lr 0.000100\n",
      "2021-02-08 02:56:19 Train Loss:301.695099\n",
      "2021-02-08 02:59:07 Eval Loss: 777.199158\n",
      "2021-02-08 02:59:07 epoch 8, processed 288 samples, lr 0.000100\n",
      "2021-02-08 02:59:18 Train Loss:295.162720\n",
      "2021-02-08 03:02:06 Eval Loss: 883.078979\n",
      "2021-02-08 03:02:06 epoch 9, processed 324 samples, lr 0.000100\n",
      "2021-02-08 03:02:18 Train Loss:288.655701\n",
      "2021-02-08 03:05:03 Eval Loss: 990.863220\n",
      "2021-02-08 03:05:03 epoch 10, processed 360 samples, lr 0.000100\n",
      "2021-02-08 03:05:14 Train Loss:282.089294\n",
      "2021-02-08 03:07:58 Eval Loss: 1096.071533\n",
      "2021-02-08 03:07:58 epoch 11, processed 396 samples, lr 0.000100\n",
      "2021-02-08 03:08:10 Train Loss:262.183044\n",
      "2021-02-08 03:10:58 Eval Loss: 1199.775757\n",
      "2021-02-08 03:10:58 epoch 12, processed 432 samples, lr 0.000100\n",
      "2021-02-08 03:11:07 Train Loss:258.074402\n",
      "2021-02-08 03:13:57 Eval Loss: 1306.565430\n",
      "2021-02-08 03:13:57 epoch 13, processed 468 samples, lr 0.000100\n",
      "2021-02-08 03:14:09 Train Loss:246.010773\n",
      "2021-02-08 03:16:56 Eval Loss: 1406.679199\n",
      "2021-02-08 03:16:56 epoch 14, processed 504 samples, lr 0.000100\n",
      "2021-02-08 03:17:07 Train Loss:231.738419\n",
      "2021-02-08 03:19:56 Eval Loss: 1502.005737\n",
      "2021-02-08 03:19:56 epoch 15, processed 540 samples, lr 0.000100\n",
      "2021-02-08 03:20:07 Train Loss:210.107147\n",
      "2021-02-08 03:22:55 Eval Loss: 1593.862305\n",
      "2021-02-08 03:22:55 epoch 16, processed 576 samples, lr 0.000100\n",
      "2021-02-08 03:23:07 Train Loss:193.890518\n",
      "2021-02-08 03:25:55 Eval Loss: 1686.241333\n",
      "2021-02-08 03:25:55 epoch 17, processed 612 samples, lr 0.000100\n",
      "2021-02-08 03:26:08 Train Loss:189.147369\n",
      "2021-02-08 03:28:53 Eval Loss: 1772.528320\n",
      "2021-02-08 03:28:53 epoch 18, processed 648 samples, lr 0.000100\n",
      "2021-02-08 03:29:04 Train Loss:162.508682\n",
      "2021-02-08 03:31:55 Eval Loss: 1861.910400\n",
      "2021-02-08 03:31:55 epoch 19, processed 684 samples, lr 0.000100\n",
      "2021-02-08 03:32:07 Train Loss:150.927719\n",
      "2021-02-08 03:34:52 Eval Loss: 1950.059082\n",
      "2021-02-08 03:34:52 epoch 20, processed 720 samples, lr 0.000100\n",
      "2021-02-08 03:35:01 Train Loss:148.455627\n",
      "2021-02-08 03:37:48 Eval Loss: 2034.372803\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1): \n",
    "\n",
    "\ttrain(epoch,optimizer)\n",
    "\twith torch.no_grad():\n",
    "\t\teval_accuary = eval(epoch,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, epochs+1): \n",
    "# \twith torch.no_grad():\n",
    "# \t\teval_accuary = test(epoch,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_loader(loader, image_name):\n",
    "#     image = Image.open(image_name)\n",
    "#     image = loader(image).float()\n",
    "#     image = torch.tensor(image, requires_grad=True)\n",
    "#     image = image.unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# data_transforms = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "\n",
    "# model_ft = models.resnet152(pretrained=True)\n",
    "# model_ft.eval()\n",
    "\n",
    "# print( np.argmax(model_ft(image_loader(data_transforms, $FILENAME)).detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unique_file(basename, ext):\n",
    "#     actualname = \"%s.%s\" % (basename, ext)\n",
    "#     c = itertools.count()\n",
    "#     while os.path.exists(actualname):\n",
    "#         actualname = \"%s (%d).%s\" % (basename, next(c), ext)\n",
    "#     return actualname\n",
    "# #usage:\n",
    "# for i in range(5):\n",
    "#     with open(unique_file(\"foo\", \"txt\"), \"w\") as f:\n",
    "#         f.write(str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
