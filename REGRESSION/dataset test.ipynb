{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# encoding: utf-8\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_list = list(range(0,1999))\n",
    "# vid_length = 1999\n",
    "# Start = random.randint(0,vid_length)\n",
    "# Stop = 5\n",
    "# a = vid_list[Start:Start+Stop]\n",
    "# a = [1646, 1647, 1648, 1649, 1650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1646, 1647, 1648, 1649, 1650]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1092]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(range(1999), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = \"/home/dua/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/\"+\"TRAIN.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trainlist, 'r') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle=True\n",
    "\n",
    "if shuffle:\n",
    "    random.shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "nSamples  = len(lines[:60]) if debug  else len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "length = 2000\n",
    "# length = None\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class listDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, root, length = None, shuffle=True,  train=False, dataset = None ,debug = False):\n",
    "#         with open(root, 'r') as file:\n",
    "#             self.lines = file.readlines()\n",
    "\n",
    "#         if shuffle:\n",
    "#             random.shuffle(self.lines)\n",
    "\n",
    "#         self.nSamples  = len(self.lines[:60]) if debug  else len(self.lines)\n",
    "\n",
    "#         self.train = train\n",
    "#         self.length = length\n",
    "#         self.dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __len__(self):\n",
    "#         return self.nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "assert index <= nSamples, 'index range error'\n",
    "imgpath = lines[index].rstrip()\n",
    "\n",
    "\n",
    "#         if self.train == True:\n",
    "#             img, label_index = self.load_data_label(imgpath)\n",
    "#             img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "#         else:\n",
    "#             img, label_index = self.load_test_data_label(imgpath)\n",
    "#             # img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "\n",
    "#         return (img ,label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __getitem__(self, index):\n",
    "\n",
    "#         assert index <= len(self), 'index range error'\n",
    "#         imgpath = self.lines[index].rstrip()\n",
    "\n",
    "\n",
    "#         if self.train == True:\n",
    "#             img, label_index = self.load_data_label(imgpath)\n",
    "#             img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "#         else:\n",
    "#             img, label_index = self.load_test_data_label(imgpath)\n",
    "#             # img   = torch.from_numpy(img).float()\n",
    "#             label_index = torch.LongTensor([label_index])\n",
    "\n",
    "#         return (img ,label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def load_data_label(self,imgpath):\n",
    "\n",
    "#         classes = self.get_classes()\n",
    "\n",
    "#         seq = np.zeros((224, 224, 3, self.length), dtype=np.float32)\n",
    "\n",
    "#         mean=[0.485, 0.456, 0.406]\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "\n",
    "# #         jitter = 0.2\n",
    "# #         hue = 0.1\n",
    "# #         saturation = 1.5 \n",
    "# #         exposure = 1.5\n",
    "#         jitter = 0\n",
    "#         hue = 0\n",
    "#         saturation = 0 \n",
    "#         exposure = 0\n",
    "\n",
    "#         img_path = imgpath.split(\" \")[0]\n",
    "#         label_path = imgpath.split(\" \")[1]\n",
    "#         label_index = int(classes.index(label_path))\n",
    "\n",
    "#         video_length = len(os.listdir(img_path))\n",
    "#         imgs = os.listdir(img_path)\n",
    "#         imgs.sort()\n",
    "\n",
    "#         if video_length >= self.length:\n",
    "\n",
    "#             select_frame = sorted(random.sample(range(video_length), self.length))\n",
    "#             for m in range(self.length):\n",
    "#                 img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "#                 img =  Image.open(img_file).convert('RGB')\n",
    "#                 #might need to remove data augmentation.\n",
    "#                 img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "# #                 img = data_augmentation(img, (224,224))\n",
    "#                 img = np.array(img)\n",
    "\n",
    "#                 seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "#                 seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "#                 seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "#         else:\n",
    "#             for k in range(self.length):\n",
    "#                 if k+1 <= video_length:\n",
    "#                     img_file = os.path.join(img_path,imgs[k])\n",
    "#                 else:\n",
    "#                     img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "#                 img =  Image.open(img_file).convert('RGB')\n",
    "#                 img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = np.array(img)\n",
    "\n",
    "#                 seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "#                 seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "#                 seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "                \n",
    "#         data = np.transpose(seq, (3,2,0,1))\n",
    "#         return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_data_label(self,imgpath):\n",
    "\n",
    "        classes = self.get_classes()\n",
    "\n",
    "        seq = np.zeros((224, 224, 3, self.length), dtype=np.float32)\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "\n",
    "        jitter = 0.2\n",
    "        hue = 0.1\n",
    "        saturation = 1.5 \n",
    "        exposure = 1.5\n",
    "#         jitter = 0\n",
    "#         hue = 0\n",
    "#         saturation = 0 \n",
    "#         exposure = 0\n",
    "\n",
    "        img_path = imgpath.split(\" \")[0]\n",
    "        label_path = imgpath.split(\" \")[1]\n",
    "        label_index = int(classes.index(label_path))\n",
    "\n",
    "        video_length = len(os.listdir(img_path))\n",
    "        imgs = os.listdir(img_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        if video_length >= self.length:\n",
    "\n",
    "            select_frame = sorted(random.sample(range(video_length), self.length))\n",
    "            for m in range(self.length):\n",
    "                img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "#                 img_file = os.path.join(img_path, imgs[m])\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                #might need to remove data augmentation.\n",
    "                img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = data_augmentation(img, (224,224))\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "        else:\n",
    "            for k in range(self.length):\n",
    "                if k+1 <= video_length:\n",
    "                    img_file = os.path.join(img_path,imgs[k])\n",
    "                else:\n",
    "                    img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "                \n",
    "        data = np.transpose(seq, (3,2,0,1))\n",
    "        return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for line in open('/home/dua/Desktop/GRU-test/emotion_classification-master/VGG_GRU/TrainTestlist/Emotiw/classInd.txt'):\n",
    "    classes.append(line.strip().split()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.zeros((224, 224, 3, length), dtype=np.float32)\n",
    "\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "#         jitter = 0.2\n",
    "#         hue = 0.1\n",
    "#         saturation = 1.5 \n",
    "#         exposure = 1.5\n",
    "jitter = 0\n",
    "hue = 0\n",
    "saturation = 0 \n",
    "exposure = 0\n",
    "\n",
    "img_path = imgpath.split(\" \")[0]\n",
    "label_path = imgpath.split(\" \")[1]\n",
    "label_index = int(classes.index(label_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = len(os.listdir(img_path))\n",
    "imgs = os.listdir(img_path)\n",
    "imgs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_data_label(imgpath):\n",
    "\n",
    "        seq = np.zeros((224, 224, 3, length), dtype=np.float32)\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "\n",
    "#         jitter = 0.2\n",
    "#         hue = 0.1\n",
    "#         saturation = 1.5 \n",
    "#         exposure = 1.5\n",
    "        jitter = 0\n",
    "        hue = 0\n",
    "        saturation = 0 \n",
    "        exposure = 0\n",
    "\n",
    "        img_path = img_path.split(\" \")[0]\n",
    "        label_path = img_path.split(\" \")[1]\n",
    "        label_index = int(classes.index(label_path))\n",
    "\n",
    "        video_length = len(os.listdir(img_path))\n",
    "        imgs = os.listdir(img_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        if video_length >= length:\n",
    "\n",
    "            select_frame = sorted(random.sample(range(video_length), length))\n",
    "            for m in range(length):\n",
    "                img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                #might need to remove data augmentation.\n",
    "                img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = data_augmentation(img, (224,224))\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "        else:\n",
    "            for k in range(length):\n",
    "                if k+1 <= video_length:\n",
    "                    img_file = os.path.join(img_path,imgs[k])\n",
    "                else:\n",
    "                    img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "                img =  Image.open(img_file).convert('RGB')\n",
    "                img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "                img = np.array(img)\n",
    "\n",
    "                seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "                seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "                seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "                \n",
    "        data = np.transpose(seq, (3,2,0,1))\n",
    "        return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'img_path' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-62c17386f3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-56bb3befe5c1>\u001b[0m in \u001b[0;36mload_data_label\u001b[0;34m(imgpath)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mexposure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'img_path' referenced before assignment"
     ]
    }
   ],
   "source": [
    "data ,label_index = load_data_label(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c6201f8cef64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-74ac53306d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mselect_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "if video_length >= length:\n",
    "    print\n",
    "\n",
    "    select_frame = sorted(random.sample(range(video_length), self.length))\n",
    "    for m in range(self.length):\n",
    "        img_file = os.path.join(img_path, imgs[select_frame[m]])\n",
    "        img =  Image.open(img_file).convert('RGB')\n",
    "        #might need to remove data augmentation.\n",
    "        img = data_augmentation(img, (224,224), jitter, hue, saturation, exposure)\n",
    "#                 img = data_augmentation(img, (224,224))\n",
    "        img = np.array(img)\n",
    "\n",
    "        seq[:, :, 0, m] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "        seq[:, :, 1, m] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "        seq[:, :, 2, m] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "else:\n",
    "    for k in range(length):\n",
    "        if k+1 <= video_length:\n",
    "            img_file = os.path.join(img_path,imgs[k])\n",
    "        else:\n",
    "            img_file = os.path.join(img_path,imgs[video_length-1])\n",
    "\n",
    "        img =  Image.open(img_file).convert('RGB')\n",
    "        img = data_augmentation(img,(224,224), jitter, hue, saturation, exposure)\n",
    "        img = np.array(img)\n",
    "\n",
    "        seq[:, :, 0, k] = (img[:,:,0]/255.-mean[0])/std[0]\n",
    "        seq[:, :, 1, k] = (img[:,:,1]/255.-mean[1])/std[1]\n",
    "        seq[:, :, 2, k] = (img[:,:,2]/255.-mean[2])/std[2]\n",
    "\n",
    "\n",
    "data = np.transpose(seq, (3,2,0,1))\n",
    "return data ,label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_test_data_label(self, imgpath, filter_size=16, stride=8):\n",
    "\n",
    "        data_transforms = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        classes = self.get_classes()\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "\n",
    "        img_path = imgpath.split(\" \")[0]\n",
    "        label_path = imgpath.split(\" \")[1]\n",
    "        label_index = int(classes.index(label_path))\n",
    "\n",
    "        video_length = len(os.listdir(img_path))\n",
    "        imgs = os.listdir(img_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        output = []\n",
    "        if video_length >= filter_size:\n",
    "            for i in range(0, video_length, stride):\n",
    "                if i + filter_size <= video_length:\n",
    "                    inputs = []\n",
    "                    frames_subset = imgs[i: i+filter_size]\n",
    "                    for frame in frames_subset:\n",
    "                        frame = os.path.join(img_path, frame)\n",
    "                        img = Image.open(frame)\n",
    "                        inputs.append(data_transforms(img).unsqueeze(0))\n",
    "                    output_subset = torch.cat(inputs).unsqueeze(0)\n",
    "                    output.append(output_subset)\n",
    "\n",
    "        else:\n",
    "            inputs = []\n",
    "            for k in range(filter_size):\n",
    "                if k+1 <= video_length:\n",
    "                    frame = os.path.join(img_path, imgs[k])\n",
    "                    img = Image.open(frame)\n",
    "                    inputs.append(data_transforms(img).unsqueeze(0))\n",
    "                else:\n",
    "                    frame = os.path.join(img_path, imgs[video_length-1])\n",
    "                    img = Image.open(frame)\n",
    "                    inputs.append(data_transforms(img).unsqueeze(0))\n",
    "            output_subset = torch.cat(inputs).unsqueeze(0)\n",
    "            output.append(output_subset)\n",
    "\n",
    "        output = torch.cat(output)\n",
    "\n",
    "        return output, label_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = [item for item in range(0, 2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size= 32\n",
    "for i in range(0, len(ints), chunk_size):\n",
    "    chunk = ints[i:i+chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1984,\n",
       " 1985,\n",
       " 1986,\n",
       " 1987,\n",
       " 1988,\n",
       " 1989,\n",
       " 1990,\n",
       " 1991,\n",
       " 1992,\n",
       " 1993,\n",
       " 1994,\n",
       " 1995,\n",
       " 1996,\n",
       " 1997,\n",
       " 1998]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
