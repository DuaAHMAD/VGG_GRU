{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from VGG_Face_torch import VGG_Face_torch\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "batch_size = 16\n",
    "test_batch_size =16\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "seed=1\n",
    "log_interval = 30\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_TYPE = 'Classification/'\n",
    "textMAIN = '/timo/datasets/Dua/GRU-test/Data-Combinations/'\n",
    "textPATH = textMAIN+EXP_TYPE\n",
    "COMB = ['BDI','AVEC','AVEC-BDI','AVEC-TEST','BDI-TEST']\n",
    "NUM = ['1','2','3','4','5']\n",
    "trainlist=textPATH+COMB[0]+'train'+NUM[0]+'.txt'\n",
    "testlist=textPATH+COMB[0]+'test'+NUM[0]+'.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "class DepressionDataset():\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        with open(csv_file, 'r') as file:\n",
    "            self.lines = file.readlines()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = len(self.lines)\n",
    "\n",
    "        for i in range(idx):\n",
    "            info = self.lines[i].rstrip()\n",
    "            par_name = info.split(\" \")[0]\n",
    "            label = int(info.split(\" \")[1])\n",
    "            imgs = os.listdir(par_name)\n",
    "            imgs.sort()\n",
    "            for img in range(idx):\n",
    "                img_path = par_name+\"/\"+imgs[img]\n",
    "                image = Image.fromarray(io.imread(img_path))\n",
    "#                 print(image)\n",
    "                sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            transform_img = self.transform(sample['image'])\n",
    "#             print(transform_img)\n",
    "            sample = {'image': transform_img, 'label': sample['label']}\n",
    "    \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "#                                  transforms.ToPILImage(),\n",
    "                                 transforms.Resize(256),\n",
    "                                #  transforms.RandomResizedCrop((224,224), scale=(0.875, 1.125), ratio=(1.0, 1.0)),\n",
    "                                #  transforms.CenterCrop(224),\n",
    "                                 transforms.RandomCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.507395516207, ),(0.255128989415, ))\n",
    "                                ])\n",
    "\n",
    "transform_test  = transforms.Compose([transforms.Resize(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.507395516207, ),(0.255128989415, ))\n",
    "                                ])\n",
    "\n",
    "\n",
    "# train_data = torchvision.datasets.ImageFolder('./train',transform=transform_train)\n",
    "# test_data = torchvision.datasets.ImageFolder('./test',transform=transform_test)\n",
    "train_data = DepressionDataset(csv_file = trainlist,transform=transform_train)\n",
    "test_data = DepressionDataset(csv_file = testlist,transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,   batch_size=test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class average_meter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_Net(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(VGG_Net, self).__init__()\n",
    "\n",
    "        self.pre_model = nn.Sequential(*list(model.children())[:-1])\n",
    "        # self.dropout = nn.Dropout(p=0.8)\n",
    "        self.classifier = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_model(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emotion = VGG_Face_torch\n",
    "model_emotion.load_state_dict(torch.load('VGG_Face_torch.pth'))\n",
    "model = VGG_Net(model_emotion).cuda()\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum ,weight_decay= 0.0005,nesterov=True)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=20, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    losses = average_meter()\n",
    "    accuracy = average_meter()\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx,sample in enumerate(train_loader):\n",
    "#         print(data)\n",
    "        data, target = Variable(sample['image']).cuda(), Variable(sample['label']).cuda()\n",
    "        output = model(data)\n",
    "        print(output.size())\n",
    "        loss = loss_function(output, target)\n",
    "#         print('output:',output.max(1))\n",
    "        losses.update(loss.data, data.size(0))\n",
    "#         print('max data:',output.data[1])\n",
    "        pred = output.data.max(1)[1]\n",
    "        prec = pred.eq(target.data).cpu().sum()\n",
    "        accuracy.update(float(prec) / data.size(0), data.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             print('Train Epoch: {}\\t'\n",
    "#                   'Batch: [{:5d}/{:5d} ({:3.0f}%)]\\t'                     \n",
    "#                   'Loss: {:.6f}'.format(\n",
    "#                       epoch, batch_idx * len(data), len(train_data),\n",
    "#                       100. * batch_idx / len(train_loader), losses.val))\n",
    "#             print('Training accuracy:', accuracy.val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val():\n",
    "    losses = average_meter()\n",
    "    accuracy = average_meter()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for sample in test_loader:\n",
    "\n",
    "        data, target = Variable(sample['image'],volatile=True).cuda(), Variable(sample['label'],volatile=True).cuda()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        losses.update(loss.data, data.size(0))\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        prec = pred.eq(target.data).cpu().sum()\n",
    "        accuracy.update(float(prec) / data.size(0), data.size(0))\n",
    "\n",
    "#     print('\\nTest: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "#         losses.avg, int(accuracy.sum), len(test_data), 100. * accuracy.avg))\n",
    "\n",
    "    return accuracy.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duaa/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    best_model = model\n",
    "    best_accuray = 0.0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        train(epoch)\n",
    "        val_accuracy = val()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        if best_accuray < val_accuracy:\n",
    "            best_model   = model\n",
    "            best_accuray = val_accuracy\n",
    "\n",
    "\n",
    "    print (\"The best model has an accuracy of \" + str(best_accuray))\n",
    "    torch.save(best_model.state_dict(), 'best.model')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = [0.3206, 0.3167, 0.2984, 0.2252]\n",
    "max(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
